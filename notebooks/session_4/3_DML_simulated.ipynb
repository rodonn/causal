{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few different package options\n",
    "#import DoubleML as dml # Also has R package by same authors\n",
    "import econml # Created by Microsoft\n",
    "from econml.dml import DML, LinearDML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn.linear_model import (Lasso, LassoCV, LogisticRegression,\n",
    "                                  LogisticRegressionCV,LinearRegression,\n",
    "                                  MultiTaskElasticNet,MultiTaskElasticNetCV)\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGP constants\n",
    "np.random.seed(123)\n",
    "n = 2000\n",
    "n_w = 30\n",
    "support_size = 5\n",
    "n_x = 1\n",
    "# Outcome support\n",
    "support_Y = np.random.choice(np.arange(n_w), size=support_size, replace=False)\n",
    "coefs_Y = np.random.uniform(0, 1, size=support_size)\n",
    "epsilon_sample = lambda n: np.random.uniform(-1, 1, size=n)\n",
    "# Treatment support\n",
    "support_T = support_Y\n",
    "coefs_T = np.random.uniform(0, 1, size=support_size)\n",
    "eta_sample = lambda n: np.random.uniform(-1, 1, size=n)\n",
    "\n",
    "# Generate controls, covariates, treatments and outcomes\n",
    "W = np.random.normal(0, 1, size=(n, n_w))\n",
    "X = np.random.uniform(0, 1, size=(n, n_x))\n",
    "# Heterogeneous treatment effects\n",
    "TE = np.array([exp_te(x_i) for x_i in X])\n",
    "T = np.dot(W[:, support_T], coefs_T) + eta_sample(n)\n",
    "Y = TE * T + np.dot(W[:, support_Y], coefs_Y) + epsilon_sample(n)\n",
    "\n",
    "Y_train, Y_val, T_train, T_val, X_train, X_val, W_train, W_val = train_test_split(Y, T, X, W, test_size=.2)\n",
    "# Generate test data\n",
    "X_test = np.array(list(product(np.arange(0, 1, 0.01), repeat=n_x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = LinearDML(model_y=RandomForestRegressor(),\n",
    "                model_t=RandomForestRegressor(),\n",
    "                random_state=123)\n",
    "est.fit(Y_train, T_train, X=X_train, W=W_train)\n",
    "te_pred = est.effect(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.275715  , 0.3413093 , 0.40690359, 0.47249788, 0.53809217,\n",
       "       0.60368647, 0.66928076, 0.73487505, 0.80046934, 0.86606363,\n",
       "       0.93165793, 0.99725222, 1.06284651, 1.1284408 , 1.1940351 ,\n",
       "       1.25962939, 1.32522368, 1.39081797, 1.45641226, 1.52200656,\n",
       "       1.58760085, 1.65319514, 1.71878943, 1.78438372, 1.84997802,\n",
       "       1.91557231, 1.9811666 , 2.04676089, 2.11235519, 2.17794948,\n",
       "       2.24354377, 2.30913806, 2.37473235, 2.44032665, 2.50592094,\n",
       "       2.57151523, 2.63710952, 2.70270382, 2.76829811, 2.8338924 ,\n",
       "       2.89948669, 2.96508098, 3.03067528, 3.09626957, 3.16186386,\n",
       "       3.22745815, 3.29305244, 3.35864674, 3.42424103, 3.48983532,\n",
       "       3.55542961, 3.62102391, 3.6866182 , 3.75221249, 3.81780678,\n",
       "       3.88340107, 3.94899537, 4.01458966, 4.08018395, 4.14577824,\n",
       "       4.21137254, 4.27696683, 4.34256112, 4.40815541, 4.4737497 ,\n",
       "       4.539344  , 4.60493829, 4.67053258, 4.73612687, 4.80172116,\n",
       "       4.86731546, 4.93290975, 4.99850404, 5.06409833, 5.12969263,\n",
       "       5.19528692, 5.26088121, 5.3264755 , 5.39206979, 5.45766409,\n",
       "       5.52325838, 5.58885267, 5.65444696, 5.72004126, 5.78563555,\n",
       "       5.85122984, 5.91682413, 5.98241842, 6.04801272, 6.11360701,\n",
       "       6.1792013 , 6.24479559, 6.31038989, 6.37598418, 6.44157847,\n",
       "       6.50717276, 6.57276705, 6.63836135, 6.70395564, 6.76954993])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ecdebf77f2ee3a47348d003f751c63e810ca996c1c68d1179f338200fa83b34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
